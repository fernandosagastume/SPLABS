{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Laboratorio7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOLp2s603aL6ViQAEzD87C8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernandosagastume/SPLABS/blob/master/Laboratorio7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rOY8w_zG4EK",
        "colab_type": "code",
        "outputId": "5a25fed7-8396-4282-95c8-600dab451f25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "# Install TensorFlow\n",
        "import tensorflow as tf\n",
        "#import sys\n",
        "#sys.path.append('/content/drive/My Drive/SP1/')\n",
        "\n",
        "#import the necessary packages\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5abuYf9JMS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvAutoencoder:\n",
        "  @staticmethod\n",
        "  def build(width, height, depth, filters=(64,128,256), latentDim=32):\n",
        "    # initialize the input shape to be \"channels last\" along with\n",
        "    # the channels dimension itself\n",
        "    # channels dimension itself\n",
        "    inputShape = (height, width, depth)\n",
        "    chanDim = -1\n",
        "    # define the input to the encoder\n",
        "    inputs = Input(shape=inputShape)\n",
        "    x = inputs\n",
        "    # loop over the number of filters\n",
        "    for f in filters:\n",
        "      # apply a CONV => RELU => BN operation\n",
        "      x = Conv2D(f, (3, 3), strides=1, padding=\"same\")(x)\n",
        "      x = LeakyReLU(alpha=0.2)(x)\n",
        "      x = BatchNormalization(axis=chanDim)(x)\n",
        "    # flatten the network and then construct our latent vector\n",
        "    volumeSize = K.int_shape(x)\n",
        "    print(\"volumeSize:\",volumeSize)\n",
        "    x = Flatten()(x)\n",
        "    print(\"x shape\", K.int_shape(x))\n",
        "    latent = Dense(latentDim)(x)\n",
        "    # build the encoder model\n",
        "    encoder = Model(inputs, latent, name=\"encoder\")\n",
        "    # start building the decoder model which will accept the\n",
        "    # output of the encoder as its inputs\n",
        "    latentInputs = Input(shape=(latentDim,))\n",
        "    x = Dense(np.prod(volumeSize[1:]))(latentInputs)\n",
        "    print(\"prod shape:\",np.prod(volumeSize[1:]))\n",
        "    print(\"x shape\",K.int_shape(x))\n",
        "    x = Reshape((volumeSize[1], volumeSize[2], volumeSize[3]))(x)\n",
        "    print(\"x shape\",K.int_shape(x))\n",
        "    # loop over our number of filters again, but this time in\n",
        "    # reverse order\n",
        "    for f in filters[::-1]:\n",
        "      # apply a CONV_TRANSPOSE => RELU => BN operation\n",
        "      x = Conv2DTranspose(f, (3, 3), strides=1, padding=\"same\")(x)\n",
        "      x = LeakyReLU(alpha=0.2)(x)\n",
        "      x = BatchNormalization(axis=chanDim)(x)\n",
        "    # apply a single CONV_TRANSPOSE layer used to recover the\n",
        "    # original depth of the image\n",
        "    x = Conv2DTranspose(depth, (3, 3), padding=\"same\")(x)\n",
        "    outputs = Activation(\"sigmoid\")(x)\n",
        "    # build the decoder model\n",
        "    decoder = Model(latentInputs, outputs, name=\"decoder\")\n",
        "    # our autoencoder is the encoder + decoder\n",
        "    autoencoder = Model(inputs, decoder(encoder(inputs)), name=\"autoencoder\")\n",
        "    # return a 3-tuple of the encoder, decoder, and autoencoder\n",
        "    return (encoder, decoder, autoencoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk-3TEf9MBsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "# import the necessary packages\n",
        "#from pyimagesearch.convautoencoder import ConvAutoencoder\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlPbqKpzMUWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_unsupervised_dataset(data, labels, validLabel=1,\n",
        "  anomalyLabel=3, contam=0.01, seed=42):\n",
        "    # Shapes of training set\n",
        "    print(\"Training set (images) shape: {shape}\".format(shape=data.shape))\n",
        "    # Shapes of test set\n",
        "    print(\"Training labels (images) shape: {shape}\".format(shape=labels.shape))\n",
        "    # grab all indexes of the supplied class label that are *truly*\n",
        "    # that particular label, then grab the indexes of the image\n",
        "    # labels that will serve as our \"anomalies\"\n",
        "    validIdxs = np.where(labels == validLabel)[0]\n",
        "    anomalyIdxs = np.where(labels == anomalyLabel)[0]\n",
        "    # randomly shuffle both sets of indexes\n",
        "    random.shuffle(validIdxs)\n",
        "    random.shuffle(anomalyIdxs)\n",
        "    # compute the total number of anomaly data points to select\n",
        "    i = int(len(validIdxs) * contam)\n",
        "    anomalyIdxs = anomalyIdxs[:i]\n",
        "    # use NumPy array indexing to extract both the valid images and\n",
        "    # \"anomlay\" images\n",
        "    validImages = data[validIdxs]\n",
        "    anomalyImages = data[anomalyIdxs]\n",
        "    # stack the valid images and anomaly images together to form a\n",
        "    # single data matrix and then shuffle the rows\n",
        "    images = np.vstack([validImages, anomalyImages])\n",
        "    np.random.seed(seed)\n",
        "    np.random.shuffle(images)\n",
        "    # return the set of images\n",
        "    return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tqfWWPRNerC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_predictions(decoded, gt, samples=10):\n",
        "  # initialize our list of output images\n",
        "  outputs = None\n",
        "  # loop over our number of output samples\n",
        "  for i in range(0, samples):\n",
        "    # grab the original image and reconstructed image\n",
        "    original = (gt[i] * 255).astype(\"uint8\")\n",
        "    recon = (decoded[i] * 255).astype(\"uint8\")\n",
        "  # stack the original and reconstructed image side-by-side\n",
        "  output = np.hstack([original, recon])\n",
        "  # if the outputs array is empty, initialize it as the current\n",
        "  # side-by-side image display\n",
        "  if outputs is None:\n",
        "    outputs = output\n",
        "  # otherwise, vertically stack the outputs\n",
        "  else:\n",
        "    outputs = np.vstack([outputs, output])\n",
        "  # return the output images\n",
        "  return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZpK-uT4OEg1",
        "colab_type": "code",
        "outputId": "5c3f18d7-c567-4e17-dcf8-b696a3a8b469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "# load the MNIST dataset\n",
        "print(\"loading Fashion MNIST dataset...\")\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
        "#trainX = trainX.reshape(-1, 28, 28, 1)\n",
        "#testX = testX.reshape(-1, 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading Fashion MNIST dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "birjateebPQi",
        "colab_type": "code",
        "outputId": "0e082054-1ed4-4fc4-b682-2407ebe783c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Shapes of training set\n",
        "print(\"Training set (images) shape: {shape}\".format(shape=trainX.shape))\n",
        "# Shapes of test set\n",
        "print(\"Test set (images) shape: {shape}\".format(shape=testX.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set (images) shape: (60000, 28, 28)\n",
            "Test set (images) shape: (10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOCANVdERTlL",
        "colab_type": "code",
        "outputId": "2363c32d-9e5e-4de4-d40f-8af5a60e75d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# build our unsupervised dataset of images with a small amount of\n",
        "# contamination (i.e., anomalies) added into it\n",
        "print(\"creating unsupervised dataset...\")\n",
        "images = build_unsupervised_dataset(trainX, trainY, validLabel=1,\n",
        "    anomalyLabel=3, contam=0.01)\n",
        "\n",
        "# add a channel dimension to every image in the dataset, then scale\n",
        "# the pixel intensities to the range [0, 1]\n",
        "images = np.expand_dims(images, axis=-1)\n",
        "images = images.astype(\"float32\") / 255.0\n",
        "images.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating unsupervised dataset...\n",
            "Training set (images) shape: (60000, 28, 28)\n",
            "Training labels (images) shape: (60000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6060, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fFDcDZETdhb",
        "colab_type": "code",
        "outputId": "e96a1bba-9748-4c49-f3c8-5fbf9e95f6cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# construct the training and testing split\n",
        "(trainX, testX) = train_test_split(images, test_size=0.2,\n",
        "    random_state=42)\n",
        "trainX.shape, testX.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4848, 28, 28, 1), (1212, 28, 28, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prIY1BuJSK_6",
        "colab_type": "code",
        "outputId": "68344c91-08c7-4d04-f191-f698b9672f62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# initialize the number of epochs to train for, initial learning rate,\n",
        "# and batch size\n",
        "EPOCHS = 20\n",
        "INIT_LR = 1e-3\n",
        "BS = 64\n",
        "# construct our convolutional autoencoder\n",
        "print(\"building autoencoder...\")\n",
        "(encoder, decoder, autoencoder) = ConvAutoencoder.build(28, 28, 1)\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "autoencoder.compile(loss=\"mean_squared_error\", optimizer=opt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "building autoencoder...\n",
            "volumeSize: (None, 28, 28, 256)\n",
            "x shape (None, 200704)\n",
            "prod shape: 200704\n",
            "x shape (None, 200704)\n",
            "x shape (None, 28, 28, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnHFC3wYZJAF",
        "colab_type": "code",
        "outputId": "60d540ca-564e-4607-ffed-cc6be0ae968f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.max(trainX), np.max(testX)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o83mjz6CUIo0",
        "colab_type": "code",
        "outputId": "3e9b311d-3518-4a26-fc42-d23d04e1aa14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              (None, 32)                6794016   \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 28, 28, 1)         7584513   \n",
            "=================================================================\n",
            "Total params: 14,378,529\n",
            "Trainable params: 14,376,737\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5Ap7se8Vcst",
        "colab_type": "code",
        "outputId": "1b2dcc3a-4273-4dd0-8948-9ac963ec4e4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# train the convolutional autoencoder\n",
        "H = autoencoder.fit(\n",
        "trainX, trainX, \n",
        "validation_data=(testX, testX),\n",
        "epochs=5,\n",
        "batch_size=256)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4848 samples, validate on 1212 samples\n",
            "Epoch 1/5\n",
            "4848/4848 [==============================] - 661s 136ms/sample - loss: 0.0477 - val_loss: 0.1000\n",
            "Epoch 2/5\n",
            "4848/4848 [==============================] - 654s 135ms/sample - loss: 0.0361 - val_loss: 0.0571\n",
            "Epoch 3/5\n",
            "4848/4848 [==============================] - 654s 135ms/sample - loss: 0.0280 - val_loss: 0.0919\n",
            "Epoch 4/5\n",
            "4848/4848 [==============================] - 650s 134ms/sample - loss: 0.0228 - val_loss: 0.0993\n",
            "Epoch 5/5\n",
            "4848/4848 [==============================] - 657s 135ms/sample - loss: 0.0182 - val_loss: 0.1136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qQw7_uUrCAz",
        "colab_type": "code",
        "outputId": "0f16a187-6b8f-43b9-d8f9-d4b1fa72c8c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/SP1/Lab7/')\n",
        "#use the convolutional autoencoder to make predictions on the\n",
        "# testing images, construct the visualization, and then save it\n",
        "# to disk\n",
        "print(\"making predictions...\")\n",
        "decoded = autoencoder.predict(testX)\n",
        "vis = visualize_predictions(decoded, testX)\n",
        "cv2.imwrite(\"/content/drive/My Drive/SP1/Lab7/autoencoder/encoder_vis.png\", vis)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "making predictions...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmyLysLn2_oU",
        "colab_type": "code",
        "outputId": "f81f1905-ce4b-4dfc-e836-4e96bab00195",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# construct a plot that plots and saves the training history\n",
        "loss = H.history['loss']\n",
        "val_loss = H.history['val_loss']\n",
        "epochs = range(200)\n",
        "plt.figure()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}